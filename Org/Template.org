# -*- mode:org; -*-

#+title:TITLE
#+subtitle:{{{version}}} {{{date}}}
#+author:AUTHOR
#+date:2020-02-19 11:21
#+macro:version Version 0.2.18

{{{version}}} {{{date}}}

#+texinfo:@insertcopying


* Readme
:PROPERTIES:
:unnumbered: t
:END:
- [[https://daringfireball.net/projects/markdown/][Markdown Home]]

- [[https://spec.commonmark.org/0.29/][CommonMark Spec]]

- [[https://guides.github.com/features/mastering-markdown/][Mastering Markdown]]

- [[https://github.github.com/gfm/][GitHub Flavored Markdown Spec]]

- [[https://help.github.com/en/github/writing-on-github][Writing on GitHub]]

- [[https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet][Markdown Cheatsheet]]

- [[https://guides.github.com/pdfs/markdown-cheatsheet-online.pdf][Markdown Syntax]]

- [[https://developer.github.com/v3/markdown/][GitHub REST API v3 --- Markdown]]


This Readme should be tangled and included in all git commits.  It’s purpose is
to provide an introduction to viewers of the source code on GitHub.

#+texinfo:@heading Using the ABSTRACT Entry

Each Readme should also provide an =ABSTRACT= entry for use by the ~sync~
command.  Each Org source file in a group of related ~.info~ blogs produces a
directory of linked HTML files via the ~make html~ command (which runs
~makeinfo --html <project>.texi~).  The directory of linked HTML files is
uploaded by the AWS ~make sync~ command into a separate directory of the chosen
AWS bucket for this group of related ~.info~ blogs.  Given a bucket name
~project~, and an ~.info~ blog named ~all-about-something~, with a version
number of ~v0.1.2~, the group of HTML files will be uploaded to an AWS bucket
that can be accessed like so:
: https://<project>.com/all-about-something-v0.1.2/

At the same time, the code running the ~make sync~ command will copy the text
from the =ABSTRACT= section of the Readme and create a directory at the domain
level of the AWS bucket linking to the current version of the ~index.html~ of
this subproject.  The =ABSTRACT= entry will provide some context in the
directory at the domain level, allowing the viewer to peruse the list of
~.info~ blogs and choose one based on its context.  In other words, by opening
the project domain at:
: https://<project>.com
the user will see a list of all related subprojects which link directly to the
most recently uploaded version.

#+name:project-readme
#+header: :tangle README.md
#+begin_src markdown
# TITLE
## Subtitle
## Author
## Date
## Version
# ABSTRACT
This is the Org Template file.  It is the parent of all other Org Info blogs,
and provides the source code for processing them in various different ways.
# INTRODUCTION
# CHAPTER
## Section
### Subsection
#+end_src

* Introduction
:PROPERTIES:
:unnumbered: t
:END:
** TODO Ideas on how to make this a better system
*** TODO Install major dependencies
[2020-02-14 Fri 10:12]
- [ ] like ~aws2~
- [ ] Org-mode > 9.1.9
*** TODO Get rid of hard-coded directories
- [ ] ~create-script~
  [2020-02-14 Fri 09:45]

  This script places itself inside a ~bin/~ directory so it can be found by
  searching $PATH.  This can be accomplished by creating an environment
  variable; I need to come up with a good domain name for this system first.
  How about =SyncOrg=?  So the environment variable would be =SYNC_ORG_BIN=.  A
  possible value would =~/Dev/bin= or =/usr/local/dev/bin=, depending on the
  system.
*** TODO Add check for existence of environment variables
[2020-02-14 Fri 09:57]
- [ ] it appears environment variables do not expand inside header lines? Check
  this.
- [ ] if environment variables do not expand, then need to provide a script to
  update them upon installation
- [ ] such as =SYNC_ORG_BIN=
* Chapter

* Build Tools
:PROPERTIES:
:appendix: t
:END:
** Makefile                                     :dependencies:env_vars:perl:
:PROPERTIES:
:appendix: t
:dependency1: "make"
:dependency2: "aws2; AWS Account with ~/.aws/credentials and ~/.aws/config"
:dependency3: "S3 bucket set up for serving a static web pages"
:dependency4: "GitHub Account with personal token"
:dependency5: "texinfo @6.7.0"
:env_var1: SYNC_ORG_TEMPLATE
:env_var2: EMACSLOADPATH
:env_var3: AWS_S3_BUCKET
:env_var4: GITHUB_TOKEN
:env_var5: EMACS
:env_var6: EMACS_INIT
:END:

#+name:Makefile
#+header: :tangle Makefile
#+header: :noweb tangle
#+header: :shebang "#!/usr/bin/env bash"
#+begin_src makefile

  ###############################################################################
  ### USER-DEPENDENT VARIABLES
  ### USE ENVIRONMENT VARIABLES FOR SENSITIVE DATA
  ### ALL OTHERS CAN BE HARD-CODED
  ### YOU ALSO NEED ~/.aws/credentials

  # Emacs binary and init file

  EMACS        := $(EMACS)
  EMACS_INIT   := $(EMACS_INIT)

  # The absolute path to this Template file

  TEMPLATE := $(SYNC_ORG_TEMPLATE)

  # User’s personal GitHub token for authentication
  # DO NOT HARD-CODE THIS VALUE

  GH_TOKEN := $(GITHUB_TOKEN)

  # The AWS S3 bucket to use to store the html source files

  BUCKET := s3://$(AWS_S3_BUCKET)

  # The aws command to use (version 1 or version 2)

  AWS := aws2

  # The AWS region of choice; this can also be in .aws/config

  REGION := --region us-west-2

  ### END OF USER-DEPENDENT VARIABLES
  ###############################################################################

  ### PROJ AND ORG
  # ORG is the name of this Org file with extension
  # PROJ is the name of this Org file without extension.

  ### NOTE: there can be only one Org file in the project directory;
  # so far this has not been a problem, but it might be.

  ### NOTE: S is needed only for the Template file because of the way it is nested
  # one level deep in the Templates GitHub repo, which uses the plural form
  # of Templates, whereas this file uses the singular form, Template.  So when
  # the homepage link is updated, the curl command must be told to use the plural
  # form.  This is obviously a hack only for my own use and can be removed once
  # I clean up this anomaly.

  ORG  := $(shell ls *.org)
  PROJ := $(basename $(ORG))

  ifeq ($(PROJ),$(basename $(notdir $(TEMPLATE))))
  S := s
  endif

  ### DIR:
  # This is not necessarily the same as PROJ; it is the exported .info
  # name found at #+texinfo_filename:<DIR>.info without its extension,
  # used as the directory name for the html export directory; use the
  # lowercased PROJ name if there is no texinfo_filename in the Org file

  # NOTE: 're-search-forward' will either return an error or 'nil',
  # depending on the value of the third argument, if the search fails.
  # If it returns an error, then that error shows up in the shell
  # output.  It might be advantageous to let it so you are aware that
  # there is no 'texinfo_filename', but for now it is set to return
  # 'nil' on failure, and then assign the backup value.

  DIR := $(shell $(EMACS) -Q --batch --eval '\
    (with-temp-buffer (insert-file-contents "$(ORG)") \
      (re-search-forward "^ *.\\+\\(?:texinfo_filename\\|TEXINFO_FILENAME\\):\\(.*\\).info$$" nil t) \
      (princ (match-string 1)))')
  ifeq ($(DIR),nil)
  DIR := $(shell echo $(PROJ) | tr "[:upper:]" "[:lower:]")
  endif

  ### VERS: v1.2.34/
  # The version number of this Org document.
  # If sync is run after the version number has been updated, then VERS
  # picks up the newly-changed value.  VERS used to be staticly imbedded
  # when the Makefile was tangled, but it needs to be dynamic for
  # development.

  # QUERY: should this number be formatted like this, or should it be just the numbers?
  # The reason it includes them is the S3PROJ obtains the name from the S3 bucket, and
  # it includes them.  But it only includes them because I have made it so.  Not a good
  # reason just by itself.  The ending slash is not actually a part of the version, but
  # comes from the way the 'aws2 ls' command returns its values.  So VERS should probably
  # not include the trailing slash, although it doesn’t hurt anything.

  VERS := v$(shell $(EMACS) -Q --batch --eval '\
    (with-temp-buffer (insert-file-contents "$(ORG)") \
      (re-search-forward "^ *.\\+\\(?:macro\\|MACRO\\):version Version \\(\\([[:digit:]]+[[:punct:]]?\\)\\{3\\}\\)") \
      (princ (match-string 1)))')/

  ### AWS
  # PROJ_LIST contains the list of projects currently uploaded to
  # the S3 bucket; each item contains the name of the project and its
  # current version.

  PROJ_LIST := $(strip $(filter-out PRE, $(shell $(AWS) s3 ls $(BUCKET))))

  ### S3PROJ
  # The name of the current project as obtained from S3: 'proj-v1.2.34/'
  # If there is no current project in the S3 bucket, then assign a value equal to
  # the Org project and version instead.
  ### S3VERS
  # The version of this project currently installed in the S3 bucket: 'v1.2.34/'
  # If there is no current version in the S3 bucket, then assign the version from
  # this Org file instead.

  S3PROJ := $(filter $(DIR)%,$(PROJ_LIST))
  ifeq ($(S3PROJ),$(empty))
  S3PROJ := $(DIR)-$(VERS)
  endif

  S3VERS := $(subst $(DIR)-,,$(filter $(DIR)%, $(PROJ_LIST)))
  ifeq ($(S3VERS), $(empty))
  S3VERS := $(VERS)
  endif

  ### GITHUB
  # USER is the current user's GitHub login name.

  # The user name used to be statically embedded into the Makefile
  # during tangle, but in an effort to make the Makefile dynamically
  # indepedent, dynamic code has replaced the static code.  The code
  # that placed the static name in the Makefile was a 'node' script that
  # ran in a separate Org process during tangle.  An unfortunate fact of
  # 'make' is that 'make' strips the quote marks from the string
  # obtained from the 'curl' command when the 'make shell' command
  # returns the string.  This makes the string malformed JSON and
  # unparsable by most JSON parsers, including 'node’.  However,
  # 'perl'’s core module JSON::PP (but not JSON::XS) has facilities to
  # parse very malformed JSON strings.  Therefore, this dynamic code
  # uses 'perl' and the core module JSON::PP to parse the 'curl' string
  # into a 'perl' JSON object which can return the login name.  This
  # code should work with any version of 'perl' without having to
  # install any modules.

  USER := $(shell \
		curl -sH "Authorization: token $(GH_TOKEN)" https://api.github.com/user \
		| \
		perl -MJSON::PP -e \
		    '$$/ = ""; \
		     my $$json = JSON::PP->new->loose->allow_barekey->decode(<STDIN>); \
		     print $$json->{login};' \
		)

  ### TOOLS & RESOURCES
  TOOLS  := tools
  CMPRPL := $(TOOLS)/cmprpl
  SAVE   := resources

  ### TEXINFO
  TEXI  := $(PROJ).texi
  INFO  := $(DIR).info
  PDF   := $(PROJ).pdf
  INDEX := index.html
  HTML  := $(DIR)/$(INDEX)
  DIR_OLD := $(DIR)-old

  ### AWS
  S3     := $(AWS) s3
  SRC    := $(DIR)/

  DST_OLD := $(BUCKET)/$(S3PROJ)
  DST_NEW := $(BUCKET)/$(DIR)-$(VERS)
  EXCL_INCL := --exclude "*" --include "*.html"
  GRANTS  := --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers
  S3SYNC  := $(S3) sync $(EXCL_INCL) $(SRC) $(DST_OLD) $(REGION) $(GRANTS)
  S3MOVE  := $(S3) mv --recursive $(DST_OLD) $(DST_NEW) $(REGION) $(GRANTS)

  default: check texi info html pdf

  PHONY: check default all \
	  texi info html pdf \
	  open-org open-texi open-html open-pdf \
	  clean dist-clean wiped-clean \
	  help sync update values

  values: check
	  @echo USER:   	$(USER)
	  @echo ORG:    	$(ORG)
	  @echo PROJ:   	$(PROJ) $S
	  @echo VERS:   	$(VERS)
	  @echo S3PROJ: 	$(S3PROJ)
	  @echo S3VERS: 	$(S3VERS)
	  @echo DIR:    	$(DIR)
	  @echo DIR_OLD:	$(DIR_OLD)
	  @echo SRC:    	$(SRC)
	  @echo DST_OLD:	$(DST_OLD)
	  @echo DST_NEW:	$(DST_NEW)
	  @echo PROJ_LIST:$(PROJ_LIST)

  check:
	  @[[ -z $${AWS_S3_BUCKET} ]] && \
	     { printf "$${RED}\$$AWS_S3_BUCKET $${CYAN}must be set.$${CLEAR}\n"; exit 1; } || \
	     printf "$${GREEN}AWS_S3_BUCKET: $${CYAN}$${AWS_S3_BUCKET}$${CLEAR}\n";
	  @[[ -z $${GITHUB_TOKEN} ]] && \
	     { printf "$${RED}GITHUB_TOKEN $${CYAN}must be set.$${CLEAR}\n"; exit 1; } || \
	     printf "$${GREEN}GITHUB_TOKEN: set$${CLEAR}\n";
	  @[ -d ~/.aws -a -f ~/.aws/credentials -a -f ~/.aws/config ] && \
	     printf "$${GREEN}~/.aws credentials and config: set$${CLEAR}\n" || \
	     { printf "$${RED}~/.aws 'credentials' and 'config' must be set.$${CLEAR}\n"; exit 1; }
	  @$(EMACS) --batch --load="$(EMACS_INIT)" --eval '\
		  (progn \
			  (require (quote org)) \
			  (if \
				  (member (quote texinfo) org-export-backends) \
				  (princ "texinfo backend: INSTALLED in org-export-backends") \
				  (princ "texinfo backend: NOT INSTALLED in org-export-backends")) \
			  (terpri) \
			  (if \
				  org-confirm-babel-evaluate \
				  (princ "org-confirm-babel-evaluate: SET to t; consider setting to nil") \
				  (princ "org-confirm-babel-evaluate: SET to nil")) \
			  (terpri))'

  open-org: $(ORG)
	  emacsclient $(ORG) &
  $(ORG):
	  @echo 'THERE IS NO $(ORG) FILE!!!'
	  exit 1

  texi: $(TEXI)
  $(TEXI): $(ORG)
	  $(EMACS) --batch --eval '\
	  (progn \
	    (require (quote org)) \
	    (require (quote ob-shell)) \
	    (setq org-confirm-babel-evaluate nil) \
	    (find-file "$(ORG)") \
	    (org-texinfo-export-to-texinfo))'

  open-texi: texi
	  emacsclient $(TEXI) &

  info: $(INFO)
  $(INFO): $(TEXI)
	  makeinfo $(TEXI)
  open-info: info
	  emacsclient $(INFO)

  html: $(HTML)
  $(HTML): $(TEXI)
	  makeinfo --html -o $(DIR) $(TEXI)
	  $(CMPRPL) $(DIR) $(DIR_OLD)
  open-html: html
	  open $(HTML)

  pdf: $(PDF)
  $(PDF): $(TEXI)
	  pdftexi2dvi --quiet --build=clean $(TEXI)
  open-pdf: pdf
	  open $(PDF)

  sync: $(HTML)
	  $(S3SYNC)
	  [[ $(VERS) != $(S3VERS) ]] && { $(S3MOVE); make homepage; } || :

  ### NOTE the use of the S variable at the end of PROJ; this is to handle
  # the singular case of the GitHub repo using the plural form, Templates
  # whereas the the Template.org file uses the singular form.
  homepage: $(ORG)
	  description=$(shell curl -i \
	      -H "Authorization: token $(GH_TOKEN)" \
	      https://api.github.com/repos/$(USER)/$(PROJ)$S) && \
	  curl -i \
	       -H "Authorization: token $(GH_TOKEN)" \
	       -H "Content-Type: application/json" \
	       -X PATCH \
	       -d '{"homepage":"https://$(AWS_S3_BUCKET)/$(DIR)-$(VERS)",\
		   {"description":"$(description): $(DIR)-$(VERS)"}' \
	       https://api.github.com/repos/$(USER)/$(PROJ)$S

  update: $(ORG)
	  $(EMACS) -Q --batch --eval \
	  '(progn \
	     (require (quote org)) \
	     (require (quote ob)) \
	     (require (quote ob-shell)) \
	     (find-file "$(TEMPLATE)") \
	     (goto-char (point-min)) \
	     (search-forward "* Build Tools") \
	     (org-beginning-of-line) \
	     (org-copy-subtree) \
	     (kill-buffer) \
	     (find-file "$(ORG)") \
	     (goto-char (point-min)) \
	     (search-forward "* Build Tools") \
	     (org-beginning-of-line) \
	     (org-yank) \
	     (org-cut-subtree) \
	     (save-buffer) \
	     (kill-buffer) \
	     (setq org-confirm-babel-evaluate nil) \
	     (org-babel-tangle-file "$(ORG)"))'

  ### INSTALL AWS2
  # Run this 'make' command to install the 'aws2' command-line tools into
  #   /usr/local/aws-cli;
  # this will install the commands 'aws2' and 'aws2_completer' into
  #   /usr/local/bin
  # NOTE: the install script must be run as 'root' via 'sudo' on macos to install
  #       into /usr/local
  # USAGE: sudo make install-aws2
  #        aws2 configure
  # NOTE: This should probably go into a scripts file to be run upon configuration,
  #       not in this Makefile, as it will only be needed once.  But maybe the Makefile
  #       can do all of the configuration.  Wait and see.
  install-aws2:
	  curl "https://d1vvhvl2y92vvt.cloudfront.net/awscli-exe-macos.zip" -o "awscliv2.zip"
	  unzip awscliv2.zip
	  sudo ./aws/install
	  aws2 --version

  clean:
	  -rm *~

  dist-clean: clean
	  -rm -rf *.{texi*,info*,html*,pdf*} $(DIR) $(TOOLS)
	  -for dir in *; \
	   do \
		  [ -d $$dir -a $$dir != "$(DIR_OLD)" -a $$dir != $(SAVE) ] && \
		  rm -vr $$dir; \
	   done

  wipe-clean: dist-clean
	  -rm -rf Makefile Readme.md $(DIR_OLD)

  help:
	  @echo '"make default" makes the .texi file, the .info file, \
	  the html files, and the .pdf file.'
	  @echo

	  @echo '"make check" checks for prerequistes'
	  @echo '"make values" runs check and prints variable values'
	  @echo

	  @echo '"make sync" syncs the html files in the AWS S3 bucket BUCKET; \
	  you must have your AWS S3 bucket name in the env var AWS_S3_BUCKET; \
	  You must have your AWS credentials installed in ~/.aws/credentials'
	  @echo

	  @echo '"make texi" makes the .texi file'
	  @echo '"make info" makes the .info file'
	  @echo '"make html" makes the html distribution in a subdirectory'
	  @echo '"make pdf" makes the .pdf file'
	  @echo

	  @echo '"make open-org" opens the ORG program using emacsclient for editing'
	  @echo '"make open-texi" opens the .texi file using emacsclient for review'
	  @echo '"make open-html" opens the distribution index.html file \
	  in the default web browser'
	  @echo '"make open-pdf" opens the .pdf file'
	  @echo

	  @echo '"sudo make install-aws2" installs the "aws2" command-line tools'
	  @echo 'You also need to run "aws2 configure" and supply your Access Key and Secret Access Key'

	  @echo '"make clean" removes the .texi, .info, and backup files ("*~")'
	  @echo '"make dist-clean" cleans, removes the html distribution, \
	  and removes the build directory'

#+end_src

*** TODO Next
1. The CloudFront configuration needs to be updated recognize the new version
   directory that is created as part of the ~sync~ operation.

2. Update the GitHub HOME website link for each new sync operation.

3. Store on GitHub a version of each other format upon a sync operation (i.e.,
   the INFO and PDF versions)

** Compare Replace

#+begin_comment
The following source code tangles all files during an export operation.  This
is to make sure the ~cmprpl~ source code exists in the ~tools/~ directory
before running the Makefile target =html=.  It also makes sure there is a
Makefile on an initial export.  The following code is not exported.
#+end_comment

#+name:tangle-org-file
#+header: :exports results :eval yes :results silent
#+begin_src emacs-lisp
(org-babel-tangle-file (buffer-file-name))
#+end_src

The AWS ~sync~ command relies upon time stamps to determine whether two
programs are identical or not, as well as content.  If two otherwise identical
files have different time stamps, ~sync~ will assume they are different and
will process the newer.  However, the ~texinfo~ ~makeinfo --html~ command
produces all new files even if some files (or most files) remain unchanged.
This means that all files will be uploaded to the AWS S3 bucket on every
iteration, even though the majority of the files are actually unchanged.

The ~cmprpl~ source code attempts to resolve the issue of identical exported
code having different time stamps, thus defeating the benefit provided by the
~aws2 s3 sync~ command uploading only changed files.

This program makes sure that a generated HTML directory exists: =$DIR_NEW=.  If
it doesn’t, then it is in an improper state and the program stops with an error
message.

The program then checks if an old directory exists, =$DIR_OLD=.  If one
doesn’t, then one is created by copying the current new directory.  This
provides a baseline for comparisons going forward.  The program exits at that
point.  It is very important that the =$DIR_OLD= directory not be deleted going
forward.

Given that =$DIR_OLD= exists, the program then loops through all files in
=$DIR_NEW= and compares them to the files in =$DIR_OLD=.  If the files are
identical, the =$DIR_OLD= file replaces the =$DIR_NEW= file while retaining the
old time stamp (using the ~-p~ option of ~cp~.  If a file is different, then
the =$DIR_NEW= file replaces the =$DIR_OLD= file, thus giving it updated
content and an updated time stamp.  If the file does not exist in the
=$DIR_OLD= directory, then it is added.

The program then loops through all of the files in the old directory and deletes
any that do not exist in the new directory.  Now both directories should be in
sync.

#+caption:Compare Replace program
#+name:cmprpl
#+header: :mkdirp t
#+header: :shebang "#!/usr/bin/env bash"
#+begin_src sh :tangle tools/cmprpl
  [[ $# -eq 2 ]] || { echo "ERROR: Incorrect command line arguments"; exit 1; }
  DIR_NEW=$1
  DIR_OLD=$2

  [[ -d $DIR_NEW ]] || { echo "ERROR: $DIR_NEW does not exist"; exit 1; }
  [[ -d $DIR_OLD ]] || { echo "CREATING: $DIR_OLD does not exist"; cp -a $DIR_NEW $DIR_OLD; exit 0; }

  for newfile in $DIR_NEW/*
  do
      oldfile=$DIR_OLD/$(basename $newfile)
      if [[ -e $oldfile ]]
      then
	 if cmp -s $newfile $oldfile
	 then
	     printf "${GREEN}copying OLD to NEW${CLEAR}: "
	     cp -vp $oldfile $newfile
	 else
	     printf "${PURPLE}copying NEW to OLD${CLEAR}: "
	     cp -vp $newfile $oldfile
	 fi
      else
	  printf "${BLUE}creating NEW in OLD${CLEAR}: "
	  cp -vp $newfile $oldfile
      fi
  done

  for oldfile in $DIR_OLD/*
  do
      newfile=$DIR_NEW/$(basename $oldfile)
      if [[ ! -e $newfile ]]
      then
	  printf "${RED}removing OLD${CLEAR}: "
	  rm -v $oldfile
      fi
  done
#+end_src


* Build Scripts
** Create Script                                              :dependencies:
:PROPERTIES:
:dependency1: ":tangle ~/Dev/bin/org-template"
:dependency2: "cp -v ~/Dev/Templates/Org/Template.org "$1/$1.org
:dependency3: "COLORS from profile"
:dependency4: tree
:dependency5: git
:END:
This code is a script file to create a new project from this template.  It is
called from the command line as ~org-template <project> [<author>]~.  It takes
one required, and one optional argument.  The required argument is the name of
the project.  The optional argument is the name of the author.  Here are the
steps it takes:

1. It creates a new directory in the current working directory using the
   =project= argument.

2. It copies this template into it as a new Org file using, again, the name
   of the project.

3. It then updates the title to the project name, and optionally the author,
   using the =author= argument if it was given.

4. It then deletes this script from the new Org project file.  

5. It then tangles the ~README.md~ and the ~tools/cmprpl~ files into the
   project.

6. It initializes a new Git repository, creates a basic ~.gitignore~ file in
   it, adds the Org file and the ~README.md~ file and makes an initial Git
   commit.

7. Finally, it prints an outline of the project’s structure using the ~tree~
   command.


#+caption:Create Script
#+name:create-script
#+header: :mkdirp yes
#+header: :tangle ~/Dev/bin/org-template
#+header: :shebang "#!/usr/bin/env bash"
#+begin_src sh -n
  # $1 :=: Title
  [[ ($# -eq 1) || ($# -eq 2) ]] || {
	printf "${RED}ERROR: ${YELLOW}\'org-template ${RED}<TITLE>${YELLOW} [<AUTHOR>]\'${CLEAR}"
	exit 1
  }
  printf "${PURPLE}"
  read -N 1 -p "Create new directory '$1' (y/n) ?"
  printf "${CLEAR}\n\n"
  [[ $REPLY =~ [yY] ]] && printf "${GREEN}" || exit 0

  mkdir -v "$1"
  printf "copy "
  cp -v ~/Dev/Templates/Org/Template.org "$1/$1.org"
  printf "${CLEAR}\n"

  sed -i '' -Ee '/^\#\+(title|TITLE):/ s/TITLE/'"$1"'/' \
		-Ee '/^\#\+(macro|MACRO):version Version/ s/[[:digit:].]+/0.0.0/' \
		-Ee '/^\#\+(texinfo_printed_title|TEXINFO_PRINTED_TITLE):/ s/PRINTED TITLE/'"$1"'/' \
		"$1/$1.org"
  [[ $# -eq 2 ]] && \
      sed -i '' -Ee '/^\#\+(author|AUTHOR):/ s/AUTHOR/'"$2"'/' "$1/$1.org"

  printf "${CYAN}"
  emacs --batch --eval \
    '(progn 
       (require (quote org))
       (require (quote ob))
       (require (quote ob-shell))
       (setq org-confirm-babel-evaluate nil)
       (find-file '\"$1/$1.org\"')
       (search-forward "** Create Script")
       (org-cut-subtree)
       (search-backward "** Makefile")
       (org-babel-tangle 4)
       (save-buffer 0))'

  printf "${CLEAR}\n"

  cd $1 && {
      rm *~
      printf "${YELLOWBOLD}"
      git init
      printf "${CLEAR}"

      echo "\
  .gitignore
  Makefile
  ,*~
  .*~
  ,*.texi
  ,*.info
  ,*.html
  ,*-old
  tools" > .gitignore

      git add .
      git commit -m "Initial commit of Project $1"
      git log --stat

      cd ..
      printf "${PURPLEBOLD}\n"
      pwd
      printf "${CLEAR}"
      tree -aI .git $1
  }

#+end_src
** Update Script                                                   :env_var:
:PROPERTIES:
:env_var1: (find-file-noselect (getenv "SYNC_ORG_TEMPLATE"))
:END:
This code is a script file to update the Build Tools subtree in a current
project with the updated Build Tools subtree from this template.  It copies the
outline structure of the Build Tools from this template file and yanks it into
the current project’s Org file and delete’s the old, outdated Build Tools
subtree.

Note that there is also a version of this script in the Makefile that is run
from the command line using the ~make update~ command.  This code is an
interactive Elisp function that can be loaded into memory using =C-x C-e= and
then run interactively from within the project Org as =M-x update-build-tools=.

#+captin:Update Build Tools Script
#+name:update-build-tools
#+begin_src emacs-lisp -n
  (defun update-build-tools (of-filenm)
    "Update the Build Tools of the argument file, which should be
  an Org file with a current Build Tools subtree."
    (interactive "ffile: ")
    (require (quote org))
    (save-current-buffer
	(set-buffer
	 (find-file-noselect (getenv "SYNC_ORG_TEMPLATE")))
	(save-excursion
	  (goto-char (point-min))
	  (search-forward "* Build Tools")
	  (org-beginning-of-line)
	  (org-copy-subtree))
	(set-buffer
	 (find-file-noselect of-filenm))
	(save-excursion
	  (goto-char (point-min))
	  (search-forward "* Build Tools")
	  (org-beginning-of-line)
	  (org-yank)
	  (org-cut-subtree)
	  (org-backward-heading-same-level 1)
	  (save-buffer)
	  (org-babel-tangle))))
#+end_src
** Add Readme
This script adds the README.md template to a project.  It should not be
included with the update script because once it becomes associated with a
project, it will be customized, and thus unique to the project.

#+name:add-readme
#+header: :shebang "#!/usb/bin/env bash"
#+begin_src shell
#+end_src

** Switch Emacs Init
This script allows the user to switch into using a different Emacs
initialization setup.  The script first lists the currently-selected
initialization setup, then it lists the available initialization setups, then
requests the user's choice.  After obtaining the choice, it changes the
symbolic link in =~/.emacs.d= to that chosen by the user.  Emacs is then killed
and restarted using the ~desktop-save~ feature.

Each initialization setup is a complete =~/.emacs.d= subtree, which must be set
up by the user, with its name given after a dash, such as =~/.emacs.d-original=
or =~/.emacs.d-cfbt= (“Clojure for the Brave and True”).

#+name:switch-emacs-init
#+header: :mkdirp yes
#+header: :shebang "#!/usr/bin/env bash"
#+header: :tangle ~/Dev/bin/switch-emacs-init
#+begin_src sh
  printf "${GREEN}"
  ls -l ~/.emacs.d | cut -f 12- -d ' '
  printf "${CLEAR}"
  echo
  select choice in $(ls -1d ~/.emacs.d-*) "abort"
  do
      echo -n 'You chose '
      printf " ${B_YELLOW}${F_BLACK}$choice${CLEAR}  "
      [[ $choice = "abort" ]] && exit 0
      rm ~/.emacs.d
      printf "${CYAN}"
      ln -vs $choice ~/.emacs.d
      echo
      printf "${RED}"
      read -N 1 -p "Restart Emacs now? (y/n) "
      printf "${CLEAR}\n"
      [[ $REPLY =~ y|Y ]] || { echo "Not restarting"; break; }
      echo "Restarting..."
      emacsclient --eval '(progn (desktop-save "~/.emacs.d-original/")(kill-emacs))'
      break
  done
  /Applications/MacPorts/EmacsMac.app/Contents/MacOS/Emacs --eval '(progn (server-start)(desktop-read "~/.emacs.d-original/"))' &
#+end_src

* List of Programs
:PROPERTIES:
:appendix: t
:END:
#+texinfo:@listoffloats Listing

* List of Examples
:PROPERTIES:
:appendix: t
:END:
#+texinfo:@listoffloats Example

* Copying
:PROPERTIES:
:copying:  t
:END:

Copyright \copy 2020 by {{{author}}}

* Concept Index
:PROPERTIES:
:unnumbered: t
:index:    cp
:END:

* Program Index
:PROPERTIES:
:index:    pg
:unnumbered: t
:END:

* Function Index
:PROPERTIES:
:index:    fn
:unnumbered: t
:END:

* Variable Index
:PROPERTIES:
:index:    vr
:unnumbered: t
:END:


* Footnotes


* Export Configurations                                            :noexport:

#+options: H:4

#+texinfo_class: info
#+texinfo_header:
#+texinfo_post_header:
#+texinfo_dir_category:<DIR CATEGORY>
#+texinfo_dir_title:<DIR TITLE>
#+texinfo_dir_desc:<DIR DESCRIPTION>
#+texinfo_printed_title:PRINTED TITLE


* Local Variables                                                  :noexport:
# Local Variables:
# fill-column: 79
# eval: (electric-quote-local-mode)
# indent-tabs-mode: t
# time-stamp-pattern: "8/^\\#\\+date:%:y-%02m-%02d %02H:%02M$"
# End:
