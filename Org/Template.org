# -*- mode:org; -*-

#+title:TITLE
#+subtitle:{{{version}}} {{{date}}}
#+author:AUTHOR
#+date:2020-02-02 09:57
#+macro:version Version 0.2.3

{{{version}}} {{{date}}}

#+texinfo:@insertcopying


* Readme
:PROPERTIES:
:unnumbered: t
:END:
- [[https://daringfireball.net/projects/markdown/][Markdown Home]]

- [[https://spec.commonmark.org/0.29/][CommonMark Spec]]

- [[https://guides.github.com/features/mastering-markdown/][Mastering Markdown]]

- [[https://github.github.com/gfm/][GitHub Flavored Markdown Spec]]

- [[https://help.github.com/en/github/writing-on-github][Writing on GitHub]]

- [[https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet][Markdown Cheatsheet]]

- [[https://guides.github.com/pdfs/markdown-cheatsheet-online.pdf][Markdown Syntax]]

- [[https://developer.github.com/v3/markdown/][GitHub REST API v3 --- Markdown]]


This Readme should be tangled and included in all git commits.  It’s purpose is
to provide an introduction to viewers of the source code on GitHub.

#+texinfo:@heading Using the ABSTRACT Entry

Each Readme should also provide an =ABSTRACT= entry for use by the ~sync~
command.  Each Org source file in a group of related ~.info~ blogs produces a
directory of linked HTML files via the ~make html~ command (which runs
~makeinfo --html <project>.texi~).  The directory of linked HTML files is
uploaded by the AWS ~make sync~ command into a separate directory of the chosen
AWS bucket for this group of related ~.info~ blogs.  Given a bucket name
~project~, and an ~.info~ blog named ~all-about-something~, with a version
number of ~v0.1.2~, the group of HTML files will be uploaded to an AWS bucket
that can be accessed like so:
: https://<project>.com/all-about-something-v0.1.2/

At the same time, the code running the ~make sync~ command will copy the text
from the =ABSTRACT= section of the Readme and create a directory at the domain
level of the AWS bucket linking to the current version of the ~index.html~ of
this subproject.  The =ABSTRACT= entry will provide some context in the
directory at the domain level, allowing the viewer to peruse the list of
~.info~ blogs and choose one based on its context.  In other words, by opening
the project domain at:
: https://<project>.com
the user will see a list of all related subprojects which link directly to the
most recently uploaded version.

#+name:projec-readme
#+header: :tangle README.md
#+begin_src markdown
# TITLE
## Subtitle
## Author
## Date
## Version
# ABSTRACT
This is the Org Template file.  It is the parent of all other Org Info blogs,
and provides the source code for processing them in various different ways.
# INTRODUCTION
# CHAPTER
## Section
### Subsection
#+end_src

* Introduction
:PROPERTIES:
:unnumbered: t
:END:

* Chapter

* Build Tools
:PROPERTIES:
:appendix: t
:END:

** Makefile                                     :dependencies:env_vars:perl:
:PROPERTIES:
:appendix: t
:dependency1: "make"
:dependency2: "AWS Account with ~/.aws/credentials and ~/.aws/config"
:dependency3: "S3 bucket set up for serving a static web pages"
:dependency4: "GitHub Account with personal token"
:env_var1: ORG_TEMPLATE
:env_var2: EMACSLOADPATH
:env_var3: AWS_S3_BUCKET
:env_var4: GITHUB_TOKEN
:END:

#+name:Makefile
#+header: :tangle Makefile
#+header: :noweb tangle
#+header: :shebang "#!/usr/bin/env bash"
#+begin_src makefile

  ###############################################################################
  ### USER-DEPENDENT VARIABLES
  ### USE ENVIRONMENT VARIABLES FOR SENSITIVE DATA
  ### ALL OTHERS CAN BE HARD-CODED
  ### YOU ALSO NEED ~/.aws/credentials

  EMACS   := /Applications/MacPorts/EmacsMac.app/Contents/MacOS/bin/emacs-26.3
  EMACS_D := $(HOME)/.emacs.d
  INIT_EL := init.el

  # The fully-qualified path to the Template file

  TEMPLATE := $(ORG_TEMPLATE)

  # User’s personal GitHub token for authentication
  # DO NOT HARD-CODE THIS VALUE

  TOKEN := $(GITHUB_TOKEN)

  # The AWS S3 bucket to use to store the html source files

  BUCKET := s3://$(AWS_S3_BUCKET)

  # The aws command to use (version 1 or version 2)

  AWS := aws2

  # The AWS region of choice; this can also be in .aws/config

  REGION := --region us-west-2

  ### END OF USER-DEPENDENT VARIABLES
  ###############################################################################

  ### ORG
  ### NOTE: there can be only one Org file in the directory;
  ### so far this has not been a problem, but it might be.

  PROJ := $(basename $(shell ls *.org))
  ORG   := $(PROJ).org

  # DIR is not necessarily the same as PROJ; it is the exported .info
  # name found at #+texinfo_filename:<DIR>.info without its extension,
  # used as the directory name for the html exports; use the lowercased
  # PROJ name if there is no texinfo_filename in the Org file 

  DIR := $(shell sed -nEe '/^\#\+texinfo_filename:(.*)\.info/ { s//\1/p; q; }' $(ORG))
  DIR ?= $(shell echo $(PROJ) | tr "[:upper:]" "[:lower:]")

  # VERS
  # The version number of this Org document.
  # If sync is run after the version number has been updated, then VERS
  # picks up the newly-changed value.  VERS used to be staticly imbedded
  # when the Makefile was tangled, but it needs to be dynamic for
  # development.

  VERS := $(shell sed -Ene '/^\#\+macro:version Version (([[:digit:]]+[[:punct:]]?){3})/ { s//v\1\//p; q; }' $(ORG))

  ### AWS
  # PROJ_LIST contains the list of projects currently uploaded to
  # the S3 bucket; each item contains the name of the project and its
  # current version.

  PROJ_LIST := $(strip $(filter-out PRE, $(shell $(AWS) s3 ls $(BUCKET))))

  # S3PROJ is the name of the current project as obtained from S3
  # S3VERS is the version of this project currently installed in the S3 bucket

  S3PROJ := $(filter $(DIR)%,$(PROJ_LIST))
  S3VERS := $(subst $(DIR)-,,$(filter $(DIR)%, $(PROJ_LIST)))

  ### GITHUB
  # USER is the current user's GitHub login name.

  # The user name used to be statically embedded into the Makefile
  # during tangle, but in an effort to make the Makefile dynamically
  # indepedent, dynamic code has replaced the static code.  The code
  # that placed the static name in the Makefile was a 'node' script that
  # ran in a separate Org process during tangle.  An unfortunate fact of
  # 'make' is that 'make' strips the quote marks from the string
  # obtained from the 'curl' command when the 'make shell' command
  # returns the string.  This makes the string malformed JSON and
  # unparsable by most JSON parsers, including 'node’.  However,
  # 'perl'’s core module JSON::PP (but not JSON::XS) has facilities to
  # parse very malformed JSON strings.  Therefore, this dynamic code
  # uses 'perl' and the core module JSON::PP to parse the 'curl' string
  # into a 'perl' JSON object which can return the login name.  This
  # code should work with any version of 'perl' without having to
  # install any modules.

  USER := $(shell \
		curl -sH "Authorization: token $(TOKEN)" https://api.github.com/user \
		| \
		perl -MJSON::PP -e \
		    '$$/ = ""; \
		     my $$json = JSON::PP->new->loose->allow_barekey->decode(<STDIN>); \
		     print $$json->{login};' \
		)

  ### TOOLS & RESOURCES
  TOOLS  := tools
  CMPRPL := $(TOOLS)/cmprpl
  SAVE   := resources

  ### TEXINFO
  TEXI  := $(PROJ).texi
  INFO  := $(DIR).info
  PDF   := $(PROJ).pdf
  INDEX := index.html
  HTML  := $(DIR)/$(INDEX)
  DIR_OLD := $(DIR)-old

  ### AWS
  S3     := $(AWS) s3
  SRC    := $(DIR)/

  DST_OLD := $(BUCKET)/$(S3PROJ)
  DST_NEW := $(BUCKET)/$(DIR)-$(VERS)
  EXCL_INCL := --exclude "*" --include "*.html"
  GRANTS  := --grants read=uri=http://acs.amazonaws.com/groups/global/AllUsers
  S3SYNC  := $(S3) sync $(EXCL_INCL) $(SRC) $(DST_OLD) $(REGION) $(GRANTS)
  S3MOVE  := $(S3) mv --recursive $(DST_OLD) $(DST_NEW) $(REGION) $(GRANTS)

  default: check texi info html pdf

  PHONY: check default all \
	  texi info html pdf \
	  open-org open-texi open-html open-pdf \
	  clean dist-clean wiped-clean \
	  help sync update values

  values: check
	  @echo USER:   	$(USER)
	  @echo PROJ:   	$(PROJ)
	  @echo VERS:   	$(VERS)
	  @echo S3PROJ: 	$(S3PROJ)
	  @echo S3VERS: 	$(S3VERS)
	  @echo DIR:    	$(DIR)
	  @echo DIR_OLD:	$(DIR_OLD)
	  @echo SRC:    	$(SRC)
	  @echo DST_OLD:	$(DST_OLD)
	  @echo DST_NEW:	$(DST_NEW)
	  @echo PROJ_LIST:$(PROJ_LIST)

  check:
	  @[[ -z $${AWS_S3_BUCKET} ]] && \
	     { printf "$${RED}\$$AWS_S3_BUCKET $${CYAN}must be set.$${CLEAR}\n"; exit 1; } || \
	     printf "$${GREEN}AWS_S3_BUCKET: $${CYAN}$${AWS_S3_BUCKET}$${CLEAR}\n";
	  @[[ -z $${GITHUB_TOKEN} ]] && \
	     { printf "$${RED}GITHUB_TOKEN $${CYAN}must be set.$${CLEAR}\n"; exit 1; } || \
	     printf "$${GREEN}GITHUB_TOKEN: set$${CLEAR}\n";
	  @[ -d ~/.aws -a -f ~/.aws/credentials -a -f ~/.aws/config ] && \
	     printf "$${GREEN}~/.aws credentials and config: set$${CLEAR}\n" || \
	     { printf "$${RED}~/.aws 'credentials' and 'config' must be set.$${CLEAR}\n"; exit 1; }
	  @$(EMACS) --batch --load="$(EMACS_D)/$(INIT_EL)" --eval '\
		  (progn \
			  (if \
				  (member (quote texinfo) org-export-backends) \
				  (princ "texinfo backend: INSTALLED in org-export-backends") \
				  (princ "texinfo backend: NOT INSTALLED in org-export-backends")) \
			  (terpri) \
			  (if \
				  org-confirm-babel-evaluate \
				  (princ "org-confirm-babel-evaluate: SET to t; consider setting to nil") \
				  (princ "org-confirm-babel-evaluate: SET to nil")) \
			  (terpri))'

  open-org: $(ORG)
	  emacsclient $(ORG) &
  $(ORG):
	  @echo 'THERE IS NO $(ORG) FILE!!!'
	  exit 1

  texi: $(TEXI)
  $(TEXI): $(ORG)
	  $(EMACS) --batch --eval '\
	  (progn \
	    (require (quote org)) \
	    (require (quote ob-shell)) \
	    (setq org-confirm-babel-evaluate nil) \
	    (find-file "$(ORG)") \
	    (org-texinfo-export-to-texinfo))'

  open-texi: texi
	  emacsclient $(TEXI) &

  info: $(INFO)
  $(INFO): $(TEXI)
	  makeinfo $(TEXI)
  open-info: info
	  emacsclient $(INFO)

  html: $(HTML)
  $(HTML): $(TEXI)
	  makeinfo --html $(TEXI)
	  $(CMPRPL) $(DIR) $(DIR_OLD)
  open-html: html
	  open $(HTML)

  pdf: $(PDF)
  $(PDF): $(TEXI)
	  pdftexi2dvi --quiet --build=clean $(TEXI)
  open-pdf: pdf
	  open $(PDF)

  sync: $(HTML)
	  $(S3SYNC)
	  [[ $(VERS) != $(S3VERS) ]] && { $(S3MOVE); make homepage; } || :

  homepage: $(ORG)
	  curl -i \
	       -H "Authorization: token $(TOKEN)" \
	       -H "Content-Type: application/json" \
	       -X PATCH \
	       -d '{"homepage":"https://$(AWS_S3_BUCKET)/$(DIR)-$(VERS)"}' \
	       https://api.github.com/repos/$(USER)/$(PROJ)

  update: $(ORG)
	  $(EMACS) -Q --batch --eval \
	  '(progn \
	     (require (quote org)) \
	     (require (quote ob)) \
	     (require (quote ob-shell)) \
	     (find-file "$(TEMPLATE)") \
	     (goto-char (point-min)) \
	     (search-forward "* Build Tools") \
	     (org-beginning-of-line) \
	     (org-copy-subtree) \
	     (kill-buffer) \
	     (find-file "$(ORG)") \
	     (goto-char (point-min)) \
	     (search-forward "* Build Tools") \
	     (org-beginning-of-line) \
	     (org-yank) \
	     (org-cut-subtree) \
	     (save-buffer) \
	     (kill-buffer) \
	     (setq org-confirm-babel-evaluate nil) \
	     (org-babel-tangle-file "$(ORG)"))'

  clean:
	  -rm *~

  dist-clean: clean
	  -rm -rf *.{texi*,info*,html*,pdf*} $(DIR) $(TOOLS)
	  -for dir in *; \
	   do \
		  [ -d $$dir -a $$dir != "$(DIR_OLD)" -a $$dir != $(SAVE) ] && \
		  rm -vr $$dir; \
	   done

  wipe-clean: dist-clean
	  -rm -rf Makefile Readme.md $(DIR_OLD)

  help:
	  @echo '"make default" makes the .texi file, the .info file, \
	  the html files, and the .pdf file.'
	  @echo

	  @echo '"make check" checks for prerequistes'
	  @echo '"make values" runs check and prints variable values'
	  @echo

	  @echo '"make sync" syncs the html files in the AWS S3 bucket BUCKET; \
	  you must have your AWS S3 bucket name in the env var AWS_S3_BUCKET; \
	  You must have your AWS credentials installed in ~/.aws/credentials'
	  @echo

	  @echo '"make texi" makes the .texi file'
	  @echo '"make info" makes the .info file'
	  @echo '"make html" makes the html distribution in a subdirectory'
	  @echo '"make pdf" makes the .pdf file'
	  @echo

	  @echo '"make open-org" opens the ORG program using emacsclient for editing'
	  @echo '"make open-texi" opens the .texi file using emacsclient for review'
	  @echo '"make open-html" opens the distribution index.html file \
	  in the default web browser'
	  @echo '"make open-pdf" opens the .pdf file'
	  @echo

	  @echo '"make clean" removes the .texi, .info, and backup files ("*~")'
	  @echo '"make clean-dist" cleans, removes the html distribution, \
	  and removes the build directory'

#+end_src

*** TODO Next
1. The CloudFront configuration needs to be updated recognize the new version
   directory that is created as part of the ~sync~ operation.

2. Update the GitHub HOME website link for each new sync operation.

3. Store on GitHub a version of each other format upon a sync operation (i.e.,
   the INFO and PDF versions)

** Compare Replace

#+begin_comment
The following source code tangles all files during an export operation.  This
is to make sure the ~cmprpl~ source code exists in the ~tools/~ directory
before running the Makefile target =html=.  It also makes sure there is a
Makefile on an initial export.  The following code is not exported.
#+end_comment

#+name:tangle-org-file
#+header: :exports results :eval yes :results silent
#+begin_src emacs-lisp
(org-babel-tangle-file (buffer-file-name))
#+end_src

The AWS ~sync~ command relies upon time stamps to determine whether two
programs are identical or not, as well as content.  If two otherwise identical
files have different time stamps, ~sync~ will assume they are different and
will process the newer.  However, the ~texinfo~ ~makeinfo --html~ command
produces all new files even if some files (or most files) remain unchanged.
This means that all files will be uploaded to the AWS S3 bucket on every
iteration, even though the majority of the files are actually unchanged.

The ~cmprpl~ source code attempts to resolve the issue of identical exported
code having different time stamps, thus defeating the benefit provided by the
~aws2 s3 sync~ command uploading only changed files.

This program makes sure that a generated HTML directory exists: =$DIR_NEW=.  If
it doesn’t, then it is in an improper state and the program stops with an error
message.

The program then checks if an old directory exists, =$DIR_OLD=.  If one
doesn’t, then one is created by copying the current new directory.  This
provides a baseline for comparisons going forward.  The program exits at that
point.  It is very important that the =$DIR_OLD= directory not be deleted going
forward.

Given that =$DIR_OLD= exists, the program then loops through all files in
=$DIR_NEW= and compares them to the files in =$DIR_OLD=.  If the files are
identical, the =$DIR_OLD= file replaces the =$DIR_NEW= file while retaining the
old time stamp (using the ~-p~ option of ~cp~.  If a file is different, then
the =$DIR_NEW= file replaces the =$DIR_OLD= file, thus giving it updated
content and an updated time stamp.  If the file does not exist in the
=$DIR_OLD= directory, then it is added.

The program then loops through all of the files in the old directory and deletes
any that do not exist in the new directory.  Now both directories should be in
sync.

#+caption:Compare Replace program
#+name:cmprpl
#+header: :mkdirp t
#+header: :shebang "#!/usr/bin/env bash"
#+begin_src sh :tangle tools/cmprpl
  [[ $# -eq 2 ]] || { echo "ERROR: Incorrect command line arguments"; exit 1; }
  DIR_NEW=$1
  DIR_OLD=$2

  [[ -d $DIR_NEW ]] || { echo "ERROR: $DIR_NEW does not exist"; exit 1; }
  [[ -d $DIR_OLD ]] || { echo "CREATING: $DIR_OLD does not exist"; cp -a $DIR_NEW $DIR_OLD; exit 0; }

  for newfile in $DIR_NEW/*
  do
      oldfile=$DIR_OLD/$(basename $newfile)
      if [[ -e $oldfile ]]
      then
	 if cmp -s $newfile $oldfile
	 then
	     printf "${GREEN}copying OLD to NEW${CLEAR}: "
	     cp -vp $oldfile $newfile
	 else
	     printf "${PURPLE}copying NEW to OLD${CLEAR}: "
	     cp -vp $newfile $oldfile
	 fi
      else
	  printf "${BLUE}creating NEW in OLD${CLEAR}: "
	  cp -vp $newfile $oldfile
      fi
  done

  for oldfile in $DIR_OLD/*
  do
      newfile=$DIR_NEW/$(basename $oldfile)
      if [[ ! -e $newfile ]]
      then
	  printf "${RED}removing $oldfile${CLEAR}"
	  rm -v $oldfile
      fi
  done
#+end_src


* Build Scripts
** Create Script                                              :dependencies:
:PROPERTIES:
:dependency1: ":tangle ~/Dev/bin/org-template"
:dependency2: "cp -v ~/Dev/Templates/Org/Template.org "$1/$1.org
:END:
This code is a script file to create a new project from this template.  It is
called from the command line as ~org-template <project> [<author>].  It takes
one required, and one optional argument.  The required argument is the name of
the project.  The optional argument is the name of the author.  It creates a
new directory in the current working directory using the =project= argument,
then copies this template into it as a new Org file using, again, the name of
the project.  It then updates the title to the project name, and optionally the
author, using the =author= argument if it was given.  Finally, it deletes this
script from the new Org project file.

#+caption:Create Script
#+name:create-script
#+header: :tangle ~/Dev/bin/org-template
#+header: :shebang "#!/usr/bin/env bash"
#+header: :noweb tangle
#+begin_src sh -n
    # $1 := Title
    [[ ($# -eq 1) || ($# -eq 2) ]] || {
	  printf "${RED}ERROR: ${YELLOW}\'org-template ${RED}<TITLE>${YELLOW} [<AUTHOR>]\'${CLEAR}"
	  exit 1
    }
    printf "${PURPLE}"
    read -N 1 -p "Create new directory '$1' (y/n) ?"
    printf "${CLEAR}\n\n"
    [[ $REPLY =~ [yY] ]] && printf "${GREEN}" || exit 0

    mkdir -v "$1"
    printf "copy "
    cp -v ~/Dev/Templates/Org/Template.org "$1/$1.org"
    printf "${CLEAR}\n"

    sed -i '' -Ee '/^\#\+title:/ s/TITLE/'"$1"'/' \
		  -Ee '/^\#\+macro:version Version/ s/[[:digit:].]+/0.0.0/' \
		  -Ee '/^\#\+texinfo_printed_title:/ s/PRINTED TITLE/'"$1"'/' \
		  "$1/$1.org"
    [[ $# -eq 2 ]] && \
	sed -i '' -Ee '/^\#\+author:/ s/AUTHOR/'"$2"'/' "$1/$1.org"

    printf "${CYAN}"
    emacs --batch --eval \
      '(progn 
	 (require (quote org))
	 (require (quote ob))
	 (require (quote ob-shell))
	 (setq org-confirm-babel-evaluate nil)
	 (find-file '\"$1/$1.org\"')
	 (search-forward "** Create Script")
	 (org-cut-subtree)
	 (search-backward "** Makefile")
	 (org-babel-tangle 4)
	 (save-buffer 0))'

  printf "${CLEAR}\n"
#+end_src
** Update Script                                                   :env_var:
:PROPERTIES:
:env_var1: (find-file-noselect (getenv "ORG_TEMPLATE"))
:END:
This code is a script file to update the Build Tools subtree in a current
project with the updated Build Tools subtree from this template.  It copies the
outline structure of the Build Tools from this template file and yanks it into
the current project’s Org file and delete’s the old, outdated Build Tools
subtree.

Note that there is also a version of this script in the Makefile that is run
with the Make command ~make update~ from the command line.  This code is an
interactive Elisp function that can be loaded into memory using =C-x C-e= and
then run interactively from within the project Org as =M-x update-build-tools=.

#+name:update-build-tools
#+begin_src emacs-lisp
  (defun update-build-tools (of-filenm)
    "Update the Build Tools of the argument file, which should be
  an Org file with a current Build Tools subtree."
    (interactive "ffile: ")
    (require (quote org))
    (save-current-buffer
	(set-buffer
	 (find-file-noselect (getenv "ORG_TEMPLATE")))
	(save-excursion
	  (goto-char (point-min))
	  (search-forward "* Build Tools")
	  (org-beginning-of-line)
	  (org-copy-subtree))
	(set-buffer
	 (find-file-noselect of-filenm))
	(save-excursion
	  (goto-char (point-min))
	  (search-forward "* Build Tools")
	  (org-beginning-of-line)
	  (org-yank)
	  (org-cut-subtree)
	  (org-backward-heading-same-level 1)
	  (save-buffer)
	  (org-babel-tangle))))
#+end_src
** Switch Emacs Init
This script allows the user to switch into using a different Emacs
initialization setup.  The script first lists the currently-selected
initialization setup, then it lists the available initialization setups, then
requests the user's choice.  After obtaining the choice, it changes the
symbolic link in =~/.emacs.d= to that chosen by the user.  Emacs is then killed
and restarted using the ~desktop-save~ feature.

Each initialization setup is a complete =~/.emacs.d= subtree, which must be set
up by the user, with its name given after a dash, such as =~/.emacs.d-original=
or =~/.emacs.d-cfbt= (“Clojure for the Brave and True”).

#+name:switch-emacs-init
#+header: :shebang "#!/usr/bin/env bash"
#+header: :tangle ~/Dev/bin/switch-emacs-init
#+begin_src sh
  printf "${GREEN}"
  ls -l ~/.emacs.d | cut -f 12- -d ' '
  printf "${CLEAR}"
  echo
  select choice in $(ls -1d ~/.emacs.d-*) "abort"
  do
      echo -n You chose 
      printf " ${B_YELLOW}${F_BLACK}$choice${CLEAR}  "
      [[ $choice = "abort" ]] && exit 0
      rm ~/.emacs.d
      printf "${CYAN}"
      ln -vs $choice ~/.emacs.d
      echo
      printf "${RED}"
      read -N 1 -p "Restart Emacs now? (y/n) "
      printf "${CLEAR}\n"
      [[ $REPLY =~ y|Y ]] || { echo "Not restarting"; break; }
      echo "Restarting..."
      emacsclient --eval '(progn (desktop-save "~/.emacs.d-original/")(kill-emacs))'
      break
  done
  /Applications/MacPorts/EmacsMac.app/Contents/MacOS/Emacs --eval '(progn (server-start)(desktop-read "~/.emacs.d-original/"))' &
#+end_src

* List of Programs
:PROPERTIES:
:appendix: t
:END:
#+texinfo:@listoffloats Listing

* List of Examples
:PROPERTIES:
:appendix: t
:END:
#+texinfo:@listoffloats Example

* Copying
:PROPERTIES:
:copying:  t
:END:

Copyright \copy 2020 by {{{author}}}

* Concept Index
:PROPERTIES:
:unnumbered: t
:index:    cp
:END:

* Program Index
:PROPERTIES:
:index:    pg
:unnumbered: t
:END:

* Function Index
:PROPERTIES:
:index:    fn
:unnumbered: t
:END:

* Variable Index
:PROPERTIES:
:index:    vr
:unnumbered: t
:END:


* Footnotes


* Export Configurations                                            :noexport:
#+texinfo_filename:template.info
#+texinfo_class: info
#+texinfo_header:
#+texinfo_post_header:
#+texinfo_dir_category:<DIR CATEGORY>
#+texinfo_dir_title:<DIR TITLE>
#+texinfo_dir_desc:<DIR DESCRIPTION>
#+texinfo_printed_title:PRINTED TITLE


* Local Variables                                                  :noexport:
# Local Variables:
# fill-column: 79
# eval: (electric-quote-local-mode)
# indent-tabs-mode: t
# time-stamp-pattern: "8/^\\#\\+date:%:y-%02m-%02d %02H:%02M$"
# End:
